{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "brain.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAjwvcKftxVR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "eed95291-54f5-482d-b81d-a75c0f5d03fc"
      },
      "source": [
        "!pip install split-folders"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting split-folders\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/4b/7b282b0f9319189d71e803220748929b37d019b67b1782d14c59cb1bd940/split_folders-0.4.2-py3-none-any.whl\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yf6Z33u1kgIf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ef57f7e2-f767-4c51-f57f-45aa6b4db670"
      },
      "source": [
        "cd 'drive/My Drive/Brain'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'drive/My Drive/Brain'\n",
            "/content/drive/My Drive/Brain\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-22cs_MdRQtF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip Img_Dataset_series2.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xx4kv_Mwr2Ut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import splitfolders\n",
        "\n",
        "splitfolders.ratio(\"data\", output=\"data_split\", seed=1337, ratio=(.8, .2), group_prefix=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFVA5aDPXR47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from tensorflow.keras.applications import Xception, ResNet50, NASNetLarge, InceptionResNetV2\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.optimizers import SGD, Nadam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GAjYhXAbak0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_train = \"./data_split/train\"\n",
        "data_val = \"./data_split/val\"\n",
        "model_path = \"./model\"\n",
        "top_weights_path = os.path.join(os.path.abspath(model_path), 'top_model_weights.h5')\n",
        "final_weights_path = os.path.join(os.path.abspath(model_path), 'model_weights.h5')\n",
        "checkpoint = os.path.join(os.path.abspath(model_path), 'checkpoint.h5')\n",
        "\n",
        "n_classes = 75\n",
        "# based_model_last_block_layer_number = 403\n",
        "based_model_last_block_layer_number = 36\n",
        "# img_width, img_height = 331, 331\n",
        "img_width, img_height = 299, 299\n",
        "# img_width, img_height = 224, 224\n",
        "batch_size = 128\n",
        "n_epoch = 50\n",
        "lr = 1e-5\n",
        "momentum = 0.9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK48ybf2bk5S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a113d502-0362-40df-e1e0-48bc2f250ce9"
      },
      "source": [
        "base_model = Xception(input_shape=(img_width, img_height, 3), weights='imagenet', include_top=False)\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(2048, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "# x = Dense(2048, activation='relu')(x)\n",
        "# x = Dropout(0.5)(x)\n",
        "predictions = Dense(n_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "for i, layer in enumerate(base_model.layers):\n",
        "    layer.trainable = False\n",
        "    print(i, layer.name)\n",
        "\n",
        "# print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 input_2\n",
            "1 block1_conv1\n",
            "2 block1_conv1_bn\n",
            "3 block1_conv1_act\n",
            "4 block1_conv2\n",
            "5 block1_conv2_bn\n",
            "6 block1_conv2_act\n",
            "7 block2_sepconv1\n",
            "8 block2_sepconv1_bn\n",
            "9 block2_sepconv2_act\n",
            "10 block2_sepconv2\n",
            "11 block2_sepconv2_bn\n",
            "12 conv2d_4\n",
            "13 block2_pool\n",
            "14 batch_normalization_4\n",
            "15 add_12\n",
            "16 block3_sepconv1_act\n",
            "17 block3_sepconv1\n",
            "18 block3_sepconv1_bn\n",
            "19 block3_sepconv2_act\n",
            "20 block3_sepconv2\n",
            "21 block3_sepconv2_bn\n",
            "22 conv2d_5\n",
            "23 block3_pool\n",
            "24 batch_normalization_5\n",
            "25 add_13\n",
            "26 block4_sepconv1_act\n",
            "27 block4_sepconv1\n",
            "28 block4_sepconv1_bn\n",
            "29 block4_sepconv2_act\n",
            "30 block4_sepconv2\n",
            "31 block4_sepconv2_bn\n",
            "32 conv2d_6\n",
            "33 block4_pool\n",
            "34 batch_normalization_6\n",
            "35 add_14\n",
            "36 block5_sepconv1_act\n",
            "37 block5_sepconv1\n",
            "38 block5_sepconv1_bn\n",
            "39 block5_sepconv2_act\n",
            "40 block5_sepconv2\n",
            "41 block5_sepconv2_bn\n",
            "42 block5_sepconv3_act\n",
            "43 block5_sepconv3\n",
            "44 block5_sepconv3_bn\n",
            "45 add_15\n",
            "46 block6_sepconv1_act\n",
            "47 block6_sepconv1\n",
            "48 block6_sepconv1_bn\n",
            "49 block6_sepconv2_act\n",
            "50 block6_sepconv2\n",
            "51 block6_sepconv2_bn\n",
            "52 block6_sepconv3_act\n",
            "53 block6_sepconv3\n",
            "54 block6_sepconv3_bn\n",
            "55 add_16\n",
            "56 block7_sepconv1_act\n",
            "57 block7_sepconv1\n",
            "58 block7_sepconv1_bn\n",
            "59 block7_sepconv2_act\n",
            "60 block7_sepconv2\n",
            "61 block7_sepconv2_bn\n",
            "62 block7_sepconv3_act\n",
            "63 block7_sepconv3\n",
            "64 block7_sepconv3_bn\n",
            "65 add_17\n",
            "66 block8_sepconv1_act\n",
            "67 block8_sepconv1\n",
            "68 block8_sepconv1_bn\n",
            "69 block8_sepconv2_act\n",
            "70 block8_sepconv2\n",
            "71 block8_sepconv2_bn\n",
            "72 block8_sepconv3_act\n",
            "73 block8_sepconv3\n",
            "74 block8_sepconv3_bn\n",
            "75 add_18\n",
            "76 block9_sepconv1_act\n",
            "77 block9_sepconv1\n",
            "78 block9_sepconv1_bn\n",
            "79 block9_sepconv2_act\n",
            "80 block9_sepconv2\n",
            "81 block9_sepconv2_bn\n",
            "82 block9_sepconv3_act\n",
            "83 block9_sepconv3\n",
            "84 block9_sepconv3_bn\n",
            "85 add_19\n",
            "86 block10_sepconv1_act\n",
            "87 block10_sepconv1\n",
            "88 block10_sepconv1_bn\n",
            "89 block10_sepconv2_act\n",
            "90 block10_sepconv2\n",
            "91 block10_sepconv2_bn\n",
            "92 block10_sepconv3_act\n",
            "93 block10_sepconv3\n",
            "94 block10_sepconv3_bn\n",
            "95 add_20\n",
            "96 block11_sepconv1_act\n",
            "97 block11_sepconv1\n",
            "98 block11_sepconv1_bn\n",
            "99 block11_sepconv2_act\n",
            "100 block11_sepconv2\n",
            "101 block11_sepconv2_bn\n",
            "102 block11_sepconv3_act\n",
            "103 block11_sepconv3\n",
            "104 block11_sepconv3_bn\n",
            "105 add_21\n",
            "106 block12_sepconv1_act\n",
            "107 block12_sepconv1\n",
            "108 block12_sepconv1_bn\n",
            "109 block12_sepconv2_act\n",
            "110 block12_sepconv2\n",
            "111 block12_sepconv2_bn\n",
            "112 block12_sepconv3_act\n",
            "113 block12_sepconv3\n",
            "114 block12_sepconv3_bn\n",
            "115 add_22\n",
            "116 block13_sepconv1_act\n",
            "117 block13_sepconv1\n",
            "118 block13_sepconv1_bn\n",
            "119 block13_sepconv2_act\n",
            "120 block13_sepconv2\n",
            "121 block13_sepconv2_bn\n",
            "122 conv2d_7\n",
            "123 block13_pool\n",
            "124 batch_normalization_7\n",
            "125 add_23\n",
            "126 block14_sepconv1\n",
            "127 block14_sepconv1_bn\n",
            "128 block14_sepconv1_act\n",
            "129 block14_sepconv2\n",
            "130 block14_sepconv2_bn\n",
            "131 block14_sepconv2_act\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAm5iMhf8H44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = InceptionResNetV2(input_shape=(img_width, img_height, 3), weights='imagenet', include_top=False)\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(2048, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "# x = Dense(2048, activation='relu')(x)\n",
        "# x = Dropout(0.5)(x)\n",
        "predictions = Dense(n_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "for i, layer in enumerate(base_model.layers):\n",
        "    layer.trainable = False\n",
        "    print(i, layer.name)\n",
        "\n",
        "#print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLDhx5G2hHUB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = NASNetLarge(input_shape=(img_width, img_height, 3), weights='imagenet', include_top=False)\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(2048, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "# x = Dense(2048, activation='relu')(x)\n",
        "# x = Dropout(0.5)(x)\n",
        "predictions = Dense(n_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "for i, layer in enumerate(base_model.layers):\n",
        "    layer.trainable = False\n",
        "    # print(i, layer.name)\n",
        "\n",
        "# print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YWuSGMbc2L7c",
        "colab": {}
      },
      "source": [
        "base_model = ResNet50(input_shape=(img_width, img_height, 3), weights='imagenet', include_top=False)\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(2048, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(2048, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(n_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "for i, layer in enumerate(base_model.layers):\n",
        "    layer.trainable = False\n",
        "    print(i, layer.name)\n",
        "\n",
        "# print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQ4oTGswbqKW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3b0949bd-7469-497a-c073-18841a7aeb3d"
      },
      "source": [
        "train_datagen = image.ImageDataGenerator(rescale=1./255,\n",
        "                             rotation_range=5,\n",
        "                             shear_range=0.1,\n",
        "                             zoom_range=0.1,\n",
        "                             width_shift_range=0.3,\n",
        "                             height_shift_range=0.3,\n",
        "                             brightness_range=[0.7,1.3],\n",
        "                             horizontal_flip=True)\n",
        "\n",
        "val_datagen = image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_flow = train_datagen.flow_from_directory(\n",
        "    data_train,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "val_flow = val_datagen.flow_from_directory(\n",
        "    data_val,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "n_train = train_flow.n\n",
        "n_val = val_flow.n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2465 images belonging to 75 classes.\n",
            "Found 640 images belonging to 75 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEMxnaL2bv5L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "7e808f27-a2a9-4c25-db36-7a2df396ff2a"
      },
      "source": [
        "model.compile(optimizer='nadam', \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "callbacks_list = [\n",
        "    ModelCheckpoint(top_weights_path, monitor='val_accuracy', verbose=1, save_best_only=True),\n",
        "    EarlyStopping(monitor='val_accuracy', patience=5, verbose=0)\n",
        "]\n",
        "\n",
        "model.fit_generator(train_flow,\n",
        "                    steps_per_epoch=n_train//batch_size,\n",
        "                    epochs=int(n_epoch),\n",
        "                    validation_data=val_flow,\n",
        "                    validation_steps=n_val//batch_size,\n",
        "                    callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 4.3129 - accuracy: 0.0141\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.02344, saving model to /content/drive/My Drive/Brain/model/top_model_weights_InceptionResNetV2.h5\n",
            "19/19 [==============================] - 157s 8s/step - loss: 4.3129 - accuracy: 0.0141 - val_loss: 4.2994 - val_accuracy: 0.0234\n",
            "Epoch 2/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 4.2911 - accuracy: 0.0163\n",
            "Epoch 00002: val_accuracy did not improve from 0.02344\n",
            "19/19 [==============================] - 151s 8s/step - loss: 4.2911 - accuracy: 0.0163 - val_loss: 4.2798 - val_accuracy: 0.0156\n",
            "Epoch 3/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 4.2821 - accuracy: 0.0154\n",
            "Epoch 00003: val_accuracy did not improve from 0.02344\n",
            "19/19 [==============================] - 146s 8s/step - loss: 4.2821 - accuracy: 0.0154 - val_loss: 4.2734 - val_accuracy: 0.0156\n",
            "Epoch 4/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 4.2807 - accuracy: 0.0128\n",
            "Epoch 00004: val_accuracy did not improve from 0.02344\n",
            "19/19 [==============================] - 145s 8s/step - loss: 4.2807 - accuracy: 0.0128 - val_loss: 4.2728 - val_accuracy: 0.0172\n",
            "Epoch 5/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 4.2753 - accuracy: 0.0197\n",
            "Epoch 00005: val_accuracy did not improve from 0.02344\n",
            "19/19 [==============================] - 152s 8s/step - loss: 4.2753 - accuracy: 0.0197 - val_loss: 4.2697 - val_accuracy: 0.0234\n",
            "Epoch 6/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 4.2749 - accuracy: 0.0154\n",
            "Epoch 00006: val_accuracy did not improve from 0.02344\n",
            "19/19 [==============================] - 150s 8s/step - loss: 4.2749 - accuracy: 0.0154 - val_loss: 4.2672 - val_accuracy: 0.0141\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa0ed10fc18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YVfqHGSv2ks",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9c7e00b9-fd35-4a50-e000-2620172a969d"
      },
      "source": [
        "# model.load_weights(top_weights_path)\n",
        "model.load_weights(checkpoint)\n",
        "\n",
        "for layer in model.layers[:based_model_last_block_layer_number]:\n",
        "    layer.trainable = False\n",
        "for layer in model.layers[based_model_last_block_layer_number:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# opt = SGD(learning_rate=lr, momentum=momentum)\n",
        "opt = Nadam(learning_rate=lr)\n",
        "\n",
        "model.compile(optimizer=opt,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "callbacks_list = [\n",
        "    ModelCheckpoint(final_weights_path, monitor='val_accuracy', verbose=1, save_best_only=True),\n",
        "    EarlyStopping(monitor='val_loss', patience=5, verbose=0)\n",
        "]\n",
        "\n",
        "model.fit_generator(train_flow,\n",
        "                    steps_per_epoch=n_train//batch_size,\n",
        "                    epochs=n_epoch,\n",
        "                    validation_data=val_flow,\n",
        "                    validation_steps=n_val//batch_size,\n",
        "                    callbacks=callbacks_list)\n",
        "\n",
        "model_json = model.to_json()\n",
        "with open(os.path.join(os.path.abspath(model_path), 'model.json'), 'w') as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.5766 - accuracy: 0.8622\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.76250, saving model to /content/drive/My Drive/Brain/model/model_weights.h5\n",
            "19/19 [==============================] - 171s 9s/step - loss: 0.5766 - accuracy: 0.8622 - val_loss: 0.8704 - val_accuracy: 0.7625\n",
            "Epoch 2/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.5437 - accuracy: 0.8686\n",
            "Epoch 00002: val_accuracy improved from 0.76250 to 0.76406, saving model to /content/drive/My Drive/Brain/model/model_weights.h5\n",
            "19/19 [==============================] - 159s 8s/step - loss: 0.5437 - accuracy: 0.8686 - val_loss: 0.8547 - val_accuracy: 0.7641\n",
            "Epoch 3/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.5440 - accuracy: 0.8695\n",
            "Epoch 00003: val_accuracy did not improve from 0.76406\n",
            "19/19 [==============================] - 154s 8s/step - loss: 0.5440 - accuracy: 0.8695 - val_loss: 0.8452 - val_accuracy: 0.7594\n",
            "Epoch 4/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.5097 - accuracy: 0.8665\n",
            "Epoch 00004: val_accuracy improved from 0.76406 to 0.76562, saving model to /content/drive/My Drive/Brain/model/model_weights.h5\n",
            "19/19 [==============================] - 156s 8s/step - loss: 0.5097 - accuracy: 0.8665 - val_loss: 0.8279 - val_accuracy: 0.7656\n",
            "Epoch 5/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.4920 - accuracy: 0.8815\n",
            "Epoch 00005: val_accuracy improved from 0.76562 to 0.76719, saving model to /content/drive/My Drive/Brain/model/model_weights.h5\n",
            "19/19 [==============================] - 157s 8s/step - loss: 0.4920 - accuracy: 0.8815 - val_loss: 0.8210 - val_accuracy: 0.7672\n",
            "Epoch 6/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.4660 - accuracy: 0.8939\n",
            "Epoch 00006: val_accuracy did not improve from 0.76719\n",
            "19/19 [==============================] - 155s 8s/step - loss: 0.4660 - accuracy: 0.8939 - val_loss: 0.8100 - val_accuracy: 0.7672\n",
            "Epoch 7/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.4410 - accuracy: 0.8892\n",
            "Epoch 00007: val_accuracy improved from 0.76719 to 0.77344, saving model to /content/drive/My Drive/Brain/model/model_weights.h5\n",
            "19/19 [==============================] - 158s 8s/step - loss: 0.4410 - accuracy: 0.8892 - val_loss: 0.7998 - val_accuracy: 0.7734\n",
            "Epoch 8/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.4287 - accuracy: 0.8977\n",
            "Epoch 00008: val_accuracy improved from 0.77344 to 0.77500, saving model to /content/drive/My Drive/Brain/model/model_weights.h5\n",
            "19/19 [==============================] - 161s 8s/step - loss: 0.4287 - accuracy: 0.8977 - val_loss: 0.7949 - val_accuracy: 0.7750\n",
            "Epoch 9/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.4022 - accuracy: 0.9093\n",
            "Epoch 00009: val_accuracy did not improve from 0.77500\n",
            "19/19 [==============================] - 153s 8s/step - loss: 0.4022 - accuracy: 0.9093 - val_loss: 0.7895 - val_accuracy: 0.7750\n",
            "Epoch 10/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.3928 - accuracy: 0.9127\n",
            "Epoch 00010: val_accuracy improved from 0.77500 to 0.78125, saving model to /content/drive/My Drive/Brain/model/model_weights.h5\n",
            "19/19 [==============================] - 156s 8s/step - loss: 0.3928 - accuracy: 0.9127 - val_loss: 0.7823 - val_accuracy: 0.7812\n",
            "Epoch 11/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.3758 - accuracy: 0.9119\n",
            "Epoch 00011: val_accuracy did not improve from 0.78125\n",
            "19/19 [==============================] - 158s 8s/step - loss: 0.3758 - accuracy: 0.9119 - val_loss: 0.7716 - val_accuracy: 0.7766\n",
            "Epoch 12/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.3648 - accuracy: 0.9161\n",
            "Epoch 00012: val_accuracy improved from 0.78125 to 0.78438, saving model to /content/drive/My Drive/Brain/model/model_weights.h5\n",
            "19/19 [==============================] - 155s 8s/step - loss: 0.3648 - accuracy: 0.9161 - val_loss: 0.7673 - val_accuracy: 0.7844\n",
            "Epoch 13/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.3435 - accuracy: 0.9213\n",
            "Epoch 00013: val_accuracy did not improve from 0.78438\n",
            "19/19 [==============================] - 150s 8s/step - loss: 0.3435 - accuracy: 0.9213 - val_loss: 0.7621 - val_accuracy: 0.7812\n",
            "Epoch 14/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.3342 - accuracy: 0.9251\n",
            "Epoch 00014: val_accuracy did not improve from 0.78438\n",
            "19/19 [==============================] - 147s 8s/step - loss: 0.3342 - accuracy: 0.9251 - val_loss: 0.7560 - val_accuracy: 0.7828\n",
            "Epoch 15/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.3172 - accuracy: 0.9350\n",
            "Epoch 00015: val_accuracy did not improve from 0.78438\n",
            "19/19 [==============================] - 147s 8s/step - loss: 0.3172 - accuracy: 0.9350 - val_loss: 0.7485 - val_accuracy: 0.7828\n",
            "Epoch 16/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.3022 - accuracy: 0.9332\n",
            "Epoch 00016: val_accuracy did not improve from 0.78438\n",
            "19/19 [==============================] - 147s 8s/step - loss: 0.3022 - accuracy: 0.9332 - val_loss: 0.7453 - val_accuracy: 0.7797\n",
            "Epoch 17/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.2817 - accuracy: 0.9392\n",
            "Epoch 00017: val_accuracy improved from 0.78438 to 0.78594, saving model to /content/drive/My Drive/Brain/model/model_weights.h5\n",
            "19/19 [==============================] - 149s 8s/step - loss: 0.2817 - accuracy: 0.9392 - val_loss: 0.7421 - val_accuracy: 0.7859\n",
            "Epoch 18/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.2953 - accuracy: 0.9303\n",
            "Epoch 00018: val_accuracy did not improve from 0.78594\n",
            "19/19 [==============================] - 147s 8s/step - loss: 0.2953 - accuracy: 0.9303 - val_loss: 0.7445 - val_accuracy: 0.7844\n",
            "Epoch 19/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.2685 - accuracy: 0.9431\n",
            "Epoch 00019: val_accuracy did not improve from 0.78594\n",
            "19/19 [==============================] - 144s 8s/step - loss: 0.2685 - accuracy: 0.9431 - val_loss: 0.7419 - val_accuracy: 0.7859\n",
            "Epoch 20/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.2548 - accuracy: 0.9457\n",
            "Epoch 00020: val_accuracy did not improve from 0.78594\n",
            "19/19 [==============================] - 152s 8s/step - loss: 0.2548 - accuracy: 0.9457 - val_loss: 0.7389 - val_accuracy: 0.7859\n",
            "Epoch 21/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.2503 - accuracy: 0.9439\n",
            "Epoch 00021: val_accuracy did not improve from 0.78594\n",
            "19/19 [==============================] - 145s 8s/step - loss: 0.2503 - accuracy: 0.9439 - val_loss: 0.7357 - val_accuracy: 0.7859\n",
            "Epoch 22/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.2380 - accuracy: 0.9495\n",
            "Epoch 00022: val_accuracy improved from 0.78594 to 0.78750, saving model to /content/drive/My Drive/Brain/model/model_weights.h5\n",
            "19/19 [==============================] - 150s 8s/step - loss: 0.2380 - accuracy: 0.9495 - val_loss: 0.7324 - val_accuracy: 0.7875\n",
            "Epoch 23/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.2299 - accuracy: 0.9516\n",
            "Epoch 00023: val_accuracy improved from 0.78750 to 0.78906, saving model to /content/drive/My Drive/Brain/model/model_weights.h5\n",
            "19/19 [==============================] - 151s 8s/step - loss: 0.2299 - accuracy: 0.9516 - val_loss: 0.7400 - val_accuracy: 0.7891\n",
            "Epoch 24/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.2196 - accuracy: 0.9555\n",
            "Epoch 00024: val_accuracy improved from 0.78906 to 0.79219, saving model to /content/drive/My Drive/Brain/model/model_weights.h5\n",
            "19/19 [==============================] - 150s 8s/step - loss: 0.2196 - accuracy: 0.9555 - val_loss: 0.7396 - val_accuracy: 0.7922\n",
            "Epoch 25/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.2079 - accuracy: 0.9619\n",
            "Epoch 00025: val_accuracy did not improve from 0.79219\n",
            "19/19 [==============================] - 146s 8s/step - loss: 0.2079 - accuracy: 0.9619 - val_loss: 0.7384 - val_accuracy: 0.7859\n",
            "Epoch 26/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.1969 - accuracy: 0.9581\n",
            "Epoch 00026: val_accuracy did not improve from 0.79219\n",
            "19/19 [==============================] - 146s 8s/step - loss: 0.1969 - accuracy: 0.9581 - val_loss: 0.7396 - val_accuracy: 0.7875\n",
            "Epoch 27/50\n",
            "19/19 [==============================] - ETA: 0s - loss: 0.1837 - accuracy: 0.9653\n",
            "Epoch 00027: val_accuracy did not improve from 0.79219\n",
            "19/19 [==============================] - 146s 8s/step - loss: 0.1837 - accuracy: 0.9653 - val_loss: 0.7419 - val_accuracy: 0.7906\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}